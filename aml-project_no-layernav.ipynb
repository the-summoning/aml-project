{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13963606,"sourceType":"datasetVersion","datasetId":8901347}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport math\n\nimport textwrap\n\nfrom typing import Optional\nfrom diffusers import StableDiffusionPipeline\nfrom huggingface_hub import notebook_login\n\nimport matplotlib.pyplot as palt\nfrom PIL import Image\n\nnotebook_login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T13:48:39.407038Z","iopub.execute_input":"2025-12-03T13:48:39.407710Z","iopub.status.idle":"2025-12-03T13:49:06.497522Z","shell.execute_reply.started":"2025-12-03T13:48:39.407674Z","shell.execute_reply":"2025-12-03T13:49:06.496821Z"}},"outputs":[{"name":"stderr","text":"2025-12-03 13:48:53.126459: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764769733.280407      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764769733.326765      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abf83b6096574cbea7b3390f306b1ccb"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"pipe = StableDiffusionPipeline.from_pretrained(\n    \"Manojb/stable-diffusion-2-1-base\", # \"CompVis/stable-diffusion-v1-4\",\n    safety_checker=None,\n    torch_dtype=torch.float16\n).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T13:49:50.742246Z","iopub.execute_input":"2025-12-03T13:49:50.742520Z","iopub.status.idle":"2025-12-03T13:50:06.570179Z","shell.execute_reply.started":"2025-12-03T13:49:50.742499Z","shell.execute_reply":"2025-12-03T13:50:06.569532Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/543 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbffcac2ef8846d9aa269d3e5ece7bc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8b0e527baf47be8d66f9aa3fbcf848"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53413b1890e945d5af2db1f67fc62943"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba730c64ba2f443b8e054d81b2795d23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dca99ba6346349a2808e8830ce83f6d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"469053c5e05e4eb6bb54e820861d7716"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/807 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1b9e956d1a242428a24747337360667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/346 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e88f461d724ab0a3b326094d66d0f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddf100539db74167875fc348ce5e66bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/model.safetensors:   0%|          | 0.00/1.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea7766fa26f4e898b6fb25d418c0e14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb6e65f6c294567bc060b17069f83ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0cdd85d6f604d26a3c48855d9c90b4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"601b003009754d5e904daeee7ee057b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/911 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"771cedd5757d48d985278a60b534c1d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c7342fe4b00437999f0d6df5b0ad172"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def generate(prompts: list[str], num_inference_steps: int=30, guidance_scale: int=7.5):\n  images = pipe(prompts, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images\n\n  return images\n\n\ndef get_text_encoder_activations(pipe: StableDiffusionPipeline, prompts: list[str]):\n    inputs = pipe.tokenizer(\n        prompts,\n        padding=\"max_length\",\n        max_length=pipe.tokenizer.model_max_length,\n        truncation=True,\n        return_tensors=\"pt\"\n    ).to(pipe.text_encoder.device)\n\n    with torch.inference_mode():\n        outputs = pipe.text_encoder(**inputs, output_hidden_states=True)\n\n    return outputs.hidden_states\n\n\n\ndef get_unet_residual_stream(\n    pipe,\n    prompts: list[str],\n    batch_size: int = 3,\n    steps: int = 30,\n    guidance_scale: float = 7.5\n):\n    residuals_dict = {}\n    handles = []\n\n    def save_residuals(name):\n        def hook(module, input, output):\n            # UNet calculates noise prediction for both conditioned and unconditioned input.\n            # practically, it doubles the batch size internally, so we take first [:batch_size]\n            residual = output[1] if isinstance(output, tuple) else output\n            \n            if isinstance(residual, torch.Tensor):\n                residuals_dict.setdefault(name, []).append(residual[:batch_size].detach().cpu())\n            else:\n                residuals_dict.setdefault(name, []).extend([r[:batch_size].detach().cpu() for r in residual])\n        \n        return hook\n\n    for i, block in enumerate(pipe.unet.down_blocks):\n        for j, resnet in enumerate(block.resnets):\n            handles.append(resnet.register_forward_hook(save_residuals(f\"down_block_{i}_resnet_{j}\")))\n\n    for j, resnet in enumerate(pipe.unet.mid_block.resnets):\n        handles.append(resnet.register_forward_hook(save_residuals(f\"mid_block_resnet_{j}\")))\n\n    for i, block in enumerate(pipe.unet.up_blocks):\n        for j, resnet in enumerate(block.resnets):\n            handles.append(resnet.register_forward_hook(save_residuals(f\"up_block_{i}_resnet_{j}\")))\n\n    for i in range(0, len(prompts), batch_size):        \n        with torch.inference_mode():\n            _ = pipe(\n                prompts[i:i+batch_size],\n                num_inference_steps=steps,\n                guidance_scale=guidance_scale,\n            )\n\n    for h in handles:\n        h.remove()\n\n    return residuals_dict\n\ndef show_images(images: list[Image.Image], prompts: list[str], cols: int = 2, width: int = 40) -> None:\n    assert len(images) == len(prompts)\n\n    rows = math.ceil(len(images) / cols)\n    fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n\n    if isinstance(axes, np.ndarray):\n        axes = axes.flatten()\n    else:\n        axes = [axes]\n\n    for ax in axes[len(images):]:\n        ax.axis('off')\n\n    for ax, img, prompt in zip(axes, images, prompts):\n        ax.imshow(img)\n        ax.axis('off')\n        wrapped_prompt = \"\\n\".join(textwrap.wrap(prompt, width=width))\n        ax.text(0.5, -0.05, wrapped_prompt, fontsize=10, ha='center', va='top', transform=ax.transAxes)\n        for spine in ax.spines.values():\n            spine.set_visible(True)\n            spine.set_color('black')\n            spine.set_linewidth(1)\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T13:51:30.309429Z","iopub.execute_input":"2025-12-03T13:51:30.310168Z","iopub.status.idle":"2025-12-03T13:51:30.325378Z","shell.execute_reply.started":"2025-12-03T13:51:30.310135Z","shell.execute_reply":"2025-12-03T13:51:30.324520Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dogs_dataset = pd.read_csv('/kaggle/input/prompts-steering/dogs.csv')\n\ndog_prompts = dogs_dataset['positive'].tolist()\nnon_dog_prompts = dogs_dataset['negative'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T13:51:36.494646Z","iopub.execute_input":"2025-12-03T13:51:36.495420Z","iopub.status.idle":"2025-12-03T13:51:36.520351Z","shell.execute_reply.started":"2025-12-03T13:51:36.495395Z","shell.execute_reply":"2025-12-03T13:51:36.519577Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"batch_size = 3\nimages_no = 3 # len(dog_prompts)\n\nall_images = []\nall_prompts = []\n\nfor i in range(0, images_no, batch_size):\n    pos_batch = dog_prompts[i:i+batch_size]\n    neg_batch = non_dog_prompts[i:i+batch_size]\n\n    pos_images = generate(pos_batch)\n    neg_images = generate(neg_batch)\n\n    for p_img, n_img, p_prompt, n_prompt in zip(pos_images, neg_images, pos_batch, neg_batch):\n        all_images.append(p_img)\n        all_images.append(n_img)\n        all_prompts.append(p_prompt)\n        all_prompts.append(n_prompt)\n\nshow_images(all_images, all_prompts, cols=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#print(pipe.unet)\ndog_activations = get_unet_residual_stream(pipe, dog_prompts, batch_size=3, steps=1)\n\nfor layer_name, activation in dog_activations.items():\n    print(f'Layer {layer_name}: {len(activation)}')\n    for a in activation:\n        print(f'\\t{a.shape}') # (B, C, H, W)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T13:57:00.694022Z","iopub.execute_input":"2025-12-03T13:57:00.694628Z","iopub.status.idle":"2025-12-03T13:57:00.700232Z","shell.execute_reply.started":"2025-12-03T13:57:00.694602Z","shell.execute_reply":"2025-12-03T13:57:00.699631Z"}},"outputs":[{"name":"stdout","text":"Layer down_block_0_resnet_0: 3\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\nLayer down_block_0_resnet_1: 3\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\nLayer down_block_1_resnet_0: 3\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\nLayer down_block_1_resnet_1: 3\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\nLayer down_block_2_resnet_0: 3\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\nLayer down_block_2_resnet_1: 3\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\nLayer down_block_3_resnet_0: 3\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\nLayer down_block_3_resnet_1: 3\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\nLayer mid_block_resnet_0: 3\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\nLayer mid_block_resnet_1: 3\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\nLayer up_block_0_resnet_0: 3\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\nLayer up_block_0_resnet_1: 3\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\nLayer up_block_0_resnet_2: 3\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\n\ttorch.Size([4, 1280, 8, 8])\nLayer up_block_1_resnet_0: 3\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\nLayer up_block_1_resnet_1: 3\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\nLayer up_block_1_resnet_2: 3\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\n\ttorch.Size([4, 1280, 16, 16])\nLayer up_block_2_resnet_0: 3\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\nLayer up_block_2_resnet_1: 3\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\nLayer up_block_2_resnet_2: 3\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\n\ttorch.Size([4, 640, 32, 32])\nLayer up_block_3_resnet_0: 3\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\nLayer up_block_3_resnet_1: 3\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\nLayer up_block_3_resnet_2: 3\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\n\ttorch.Size([4, 320, 64, 64])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def contrastive_pca(X, Y, n_components=10, alpha=1e-3, whiten=False):\n    B, C, H, W = X.shape\n    D = C * H * W\n\n    X_flat = X.reshape(B, D)\n    Y_flat = Y.reshape(Y.shape[0], D)\n\n    Xc = X_flat - X_flat.mean(dim=0, keepdim=True)\n    Yc = Y_flat - Y_flat.mean(dim=0, keepdim=True)\n    X_mean = X_flat.mean(dim=0)\n\n    if whiten:\n        U, S, Vh = torch.linalg.svd(Yc / torch.sqrt(Yc.shape[0] - 1), full_matrices=False)\n        S_inv = torch.diag(1.0 / (S + alpha))\n        C_minus_inv_sqrt = Vh.T @ S_inv @ Vh\n        Xc = Xc @ C_minus_inv_sqrt\n\n    Uc, Sc, Vhc = torch.linalg.svd(Xc, full_matrices=False)\n    pcs = Vhc[:n_components]\n    pcs = pcs / torch.norm(pcs, dim=1, keepdim=True)\n\n    return pcs, X_mean","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}